{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8RvnGZABddn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "executionInfo": {
     "elapsed": 49052,
     "status": "error",
     "timestamp": 1707412164913,
     "user": {
      "displayName": "Abhijith A Pillai",
      "userId": "11444910519908800688"
     },
     "user_tz": -330
    },
    "id": "OkAXIcthDHlq",
    "outputId": "ed649687-9bdc-40c4-d92f-447cf6f15fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages (from face_recognition) (8.2.1)\n",
      "Requirement already satisfied: dlib>=19.7 in d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages (from face_recognition) (20.0.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages (from face_recognition) (2.2.6)\n",
      "Requirement already satisfied: Pillow in d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages (from face_recognition) (11.3.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "%pip install face_recognition\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1707402837954,
     "user": {
      "displayName": "Abhijith A Pillai",
      "userId": "11444910519908800688"
     },
     "user_tz": -330
    },
    "id": "ESCfxdDRDHsw"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "from torch import nn\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707402841132,
     "user": {
      "displayName": "Abhijith A Pillai",
      "userId": "11444910519908800688"
     },
     "user_tz": -330
    },
    "id": "lEbz86vEDHu9"
   },
   "outputs": [],
   "source": [
    "#Model with feature visualization\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
    "        super(Model, self).__init__()\n",
    "        model = models.resnext50_32x4d(pretrained = True)\n",
    "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
    "        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dp = nn.Dropout(0.4)\n",
    "        self.linear1 = nn.Linear(2048,num_classes)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    def forward(self, x):\n",
    "        batch_size,seq_length, c, h, w = x.shape\n",
    "        x = x.view(batch_size * seq_length, c, h, w)\n",
    "        fmap = self.model(x)\n",
    "        x = self.avgpool(fmap)\n",
    "        x = x.view(batch_size,seq_length,2048)\n",
    "        x_lstm,_ = self.lstm(x,None)\n",
    "        return fmap,self.dp(self.linear1(x_lstm[:,-1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707402843941,
     "user": {
      "displayName": "Abhijith A Pillai",
      "userId": "11444910519908800688"
     },
     "user_tz": -330
    },
    "id": "tuWpRd33DHxG"
   },
   "outputs": [],
   "source": [
    "im_size = 112\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "sm = nn.Softmax()\n",
    "inv_normalize =  transforms.Normalize(mean=-1*np.divide(mean,std),std=np.divide([1,1,1],std))\n",
    "def im_convert(tensor):\n",
    "    \"\"\" Display a tensor as an image. \"\"\"\n",
    "    image = tensor.to(\"cpu\").clone().detach()\n",
    "    image = image.squeeze()\n",
    "    image = inv_normalize(image)\n",
    "    image = image.numpy()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image.clip(0, 1)\n",
    "    cv2.imwrite('/content/drive/MyDrive/deep fake/ANIL.jpg',image*255)\n",
    "    return image\n",
    "\n",
    "def predict(model,img,path = './'):\n",
    "  fmap,logits = model(img.to('cuda'))\n",
    "  params = list(model.parameters())\n",
    "  weight_softmax = model.linear1.weight.detach().cpu().numpy()\n",
    "  logits = sm(logits)\n",
    "  _,prediction = torch.max(logits,1)\n",
    "  confidence = logits[:,int(prediction.item())].item()*100\n",
    "  print('confidence of prediction:',logits[:,int(prediction.item())].item()*100)\n",
    "  idx = np.argmax(logits.detach().cpu().numpy())\n",
    "  bz, nc, h, w = fmap.shape\n",
    "  out = np.dot(fmap[-1].detach().cpu().numpy().reshape((nc, h*w)).T,weight_softmax[idx,:].T)\n",
    "  predict = out.reshape(h,w)\n",
    "  predict = predict - np.min(predict)\n",
    "  predict_img = predict / np.max(predict)\n",
    "  predict_img = np.uint8(255*predict_img)\n",
    "  out = cv2.resize(predict_img, (im_size,im_size))\n",
    "  heatmap = cv2.applyColorMap(out, cv2.COLORMAP_JET)\n",
    "  img = im_convert(img[:,-1,:,:,:])\n",
    "  result = heatmap * 0.5 + img*0.8*255\n",
    "  cv2.imwrite('/content/drive/MyDrive/deep fake/ANIL.jpg',result)\n",
    "  result1 = heatmap * 0.5/255 + img*0.8\n",
    "  r,g,b = cv2.split(result1)\n",
    "  result1 = cv2.merge((r,g,b))\n",
    "  plt.imshow(result1)\n",
    "  plt.show()\n",
    "  return [int(prediction.item()),confidence]\n",
    "#img = train_data[100][0].unsqueeze(0)\n",
    "#predict(model,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1707402848598,
     "user": {
      "displayName": "Abhijith A Pillai",
      "userId": "11444910519908800688"
     },
     "user_tz": -330
    },
    "id": "F369dJNbDHzN"
   },
   "outputs": [],
   "source": [
    "#!pip3 install face_recognition\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "class validation_dataset(Dataset):\n",
    "    def __init__(self, video_names, sequence_length=60, transform=None):\n",
    "        self.video_names = video_names\n",
    "        self.transform = transform\n",
    "        self.count = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.video_names[idx]\n",
    "        frames = []\n",
    "        a = int(100 / self.count)\n",
    "        first_frame = np.random.randint(0, a)\n",
    "        for i, frame in enumerate(self.frame_extract(video_path)):\n",
    "            faces = face_recognition.face_locations(frame)\n",
    "            if faces:  # Proceed only if faces are detected\n",
    "                top, right, bottom, left = faces[0]\n",
    "                frame = frame[top:bottom, left:right, :]\n",
    "                frames.append(self.transform(frame))\n",
    "                if len(frames) == self.count:\n",
    "                    break\n",
    "        # Pad frames if there are not enough\n",
    "        while len(frames) < self.count:\n",
    "            frames.append(torch.zeros_like(frames[0]))\n",
    "        frames = torch.stack(frames)\n",
    "        frames = frames[:self.count]\n",
    "        return frames.unsqueeze(0)\n",
    "\n",
    "    def frame_extract(self, path):\n",
    "        vidObj = cv2.VideoCapture(path)\n",
    "        success = 1\n",
    "        while success:\n",
    "            success, image = vidObj.read()\n",
    "            if success:\n",
    "                yield image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_to_model = r\"D:\\DEEP FAKE COLOB\\model_87_acc_20_frames_final_data.pt\"\n",
    "print(os.path.exists(path_to_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "executionInfo": {
     "elapsed": 27741,
     "status": "ok",
     "timestamp": 1707404108124,
     "user": {
      "displayName": "Abhijith A Pillai",
      "userId": "11444910519908800688"
     },
     "user_tz": -330
    },
    "id": "u5RPuOwiDaiM",
    "outputId": "c138db55-121f-405c-f464-0a853c2f128e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\envs\\deepfake_conda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: D:\\DEEP FAKE COLOB\\FAKE 2.mp4\n",
      "FAKE\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "# Import your Model class, validation_dataset, etc.\n",
    "# from model_file import Model, validation_dataset\n",
    "\n",
    "# ----------------------------\n",
    "# Device setup (GPU/CPU)\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Video preprocessing\n",
    "# ----------------------------\n",
    "im_size = 112\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# Video paths\n",
    "# ----------------------------\n",
    "path_to_videos = [r\"D:\\DEEP FAKE COLOB\\FAKE 2.mp4\"]\n",
    "\n",
    "# Load dataset\n",
    "video_dataset = validation_dataset(\n",
    "    path_to_videos, sequence_length=20, transform=train_transforms\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Load model\n",
    "# ----------------------------\n",
    "model = Model(2)  # Initialize model\n",
    "path_to_model = r\"D:\\DEEP FAKE COLOB\\model_87_acc_20_frames_final_data.pt\"\n",
    "\n",
    "# Load state dict safely on CPU\n",
    "state_dict = torch.load(path_to_model, map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)  # Move model to the correct device\n",
    "\n",
    "# ----------------------------\n",
    "# Predict function\n",
    "# ----------------------------\n",
    "def predict(model, img, path='./', device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    img = img.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fmap, logits = model(img)\n",
    "    \n",
    "    prediction = logits.detach().cpu().numpy()\n",
    "    \n",
    "    # Handle batch dimension\n",
    "    if prediction.ndim > 1:\n",
    "        prediction = prediction[0]\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Prediction loop\n",
    "# ----------------------------\n",
    "for i, video_path in enumerate(path_to_videos):\n",
    "    print(f\"Processing: {video_path}\")\n",
    "    \n",
    "    video_tensor = video_dataset[i]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = predict(model, video_tensor, './', device=device)\n",
    "    \n",
    "    # Convert to predicted class\n",
    "    pred_class = prediction.argmax()\n",
    "    \n",
    "    if pred_class == 1:\n",
    "        print(\"REAL\")\n",
    "    else:\n",
    "        print(\"FAKE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Model Accuracy Checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "REAL 1.mp4: Predicted = FAKE, True = REAL\n",
      "REAL 10.mp4: Predicted = REAL, True = REAL\n",
      "REAL 2.mp4: Predicted = REAL, True = REAL\n",
      "REAL 3.mp4: Predicted = REAL, True = REAL\n",
      "REAL 4.mp4: Predicted = REAL, True = REAL\n",
      "REAL 5.mp4: Predicted = FAKE, True = REAL\n",
      "FAKE 1.mp4: Predicted = FAKE, True = FAKE\n",
      "FAKE 10.mp4: Predicted = FAKE, True = FAKE\n",
      "FAKE 2.mp4: Predicted = FAKE, True = FAKE\n",
      "FAKE 3.mp4: Predicted = REAL, True = FAKE\n",
      "FAKE 4.mp4: Predicted = FAKE, True = FAKE\n",
      "FAKE 5.mp4: Predicted = FAKE, True = FAKE\n",
      "FAKE 6.mp4: Predicted = REAL, True = FAKE\n",
      "FAKE 7.mp4: Predicted = FAKE, True = FAKE\n",
      "FAKE 8.mp4: Predicted = FAKE, True = FAKE\n",
      "FAKE 9.mp4: Predicted = REAL, True = FAKE\n",
      "\n",
      "Overall Accuracy: 68.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "# Import your Model, validation_dataset, predict functions\n",
    "# from model_file import Model, validation_dataset, predict\n",
    "\n",
    "# ----------------------------\n",
    "# Device setup\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Load model\n",
    "# ----------------------------\n",
    "model = Model(2)\n",
    "path_to_model = r\"D:\\DEEP FAKE COLOB\\model_87_acc_20_frames_final_data.pt\"\n",
    "state_dict = torch.load(path_to_model, map_location='cpu')  # load safely\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# Video transforms\n",
    "# ----------------------------\n",
    "im_size = 112\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((im_size, im_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# Accuracy function\n",
    "# ----------------------------\n",
    "def calculate_accuracy(test_folder):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for label_str in ['real', 'fake']:  # folder names\n",
    "        label = 1 if label_str == 'real' else 0\n",
    "        folder_path = os.path.join(test_folder, label_str)\n",
    "        videos = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.mp4')]\n",
    "        \n",
    "        dataset = validation_dataset(videos, sequence_length=20, transform=train_transforms)\n",
    "        \n",
    "        for i, video_tensor in enumerate(dataset):\n",
    "            prediction = predict(model, video_tensor, device=device)\n",
    "            # Ensure 1D array\n",
    "            if prediction.ndim > 1:\n",
    "                prediction = prediction[0]\n",
    "            pred_class = prediction.argmax()\n",
    "            \n",
    "            video_name = os.path.basename(videos[i])\n",
    "            pred_label = \"REAL\" if pred_class == 1 else \"FAKE\"\n",
    "            print(f\"{video_name}: Predicted = {pred_label}, True = {label_str.upper()}\")\n",
    "            \n",
    "            if pred_class == label:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f\"\\nOverall Accuracy: {accuracy*100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# ----------------------------\n",
    "# Run accuracy check\n",
    "# ----------------------------\n",
    "test_folder = r\"D:\\DEEP FAKE COLOB\\test_videos\"\n",
    "calculate_accuracy(test_folder)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMOL8PPtrnYIfP6IiEOjv4L",
   "gpuType": "T4",
   "mount_file_id": "1Mwv3ap1iPOjnToRV3cX3QOJ15P-o9Wrl",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deepfake_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
